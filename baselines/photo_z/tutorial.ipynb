{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sw/nix/store/b4q5asj8flwlgmaijgj1r6wbmnls5x8k-python-3.9.15-view/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /mnt/sw/nix/store/7bjp92vyxq4vmcm6q2kwdv325d50n362-py-torchvision-0.14.1/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "sys.path.append('../')\n",
    "from datasets import load_dataset, load_dataset_builder\n",
    "import lightning as L\n",
    "\n",
    "from astropile.utils import cross_match_datasets\n",
    "from photo_z_data_wrapper import PhotoZWrapper\n",
    "from photo_z_models import SimpleCNN, TrainingOnlyProgressBar\n",
    "from utils import split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/lparker/python_envs/astrokernel/lib/python3.9/site-packages/huggingface_hub/repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of matches:  1286\n",
      "Number of matches lost at healpix region borders:  0\n",
      "Final size of cross-matched catalog:  1286\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset Builders \n",
    "hsc_builder = load_dataset_builder('/mnt/ceph/users/polymathic/AstroPile_tiny/hsc/hsc.py', trust_remote_code=True)\n",
    "desi_builder = load_dataset_builder('/mnt/ceph/users/polymathic/AstroPile_tiny/desi/desi.py', trust_remote_code=True)\n",
    "\n",
    "# Cross-Match Datasets with AstroPile\n",
    "hsc_meets_desi = cross_match_datasets(desi_builder, hsc_builder,\n",
    "                                      matching_radius=1.0,\n",
    "                                      keep_in_memory=True,\n",
    "                                      )\n",
    "hsc_meets_desi.set_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use prebuilt split function to split the dataset (currently supports naive)\n",
    "train_dataset, test_dataset = split_dataset(hsc_meets_desi, split='naive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PhotoZWrapper for training and testing\n",
    "photo_z = PhotoZWrapper(\n",
    "    train_dataset,\n",
    "    test_dataset, \n",
    "    feature_flag='image.array', # feature flag\n",
    "    label_flag='Z',             # label flag\n",
    "    feature_dynamic_range=True,\n",
    "    label_dynamic_range=False,\n",
    "    feature_z_score=True,\n",
    "    label_z_score=True,\n",
    "    loading='iterated',         # iterated or full\n",
    "    batch_size=128, \n",
    "    num_workers=16, \n",
    "    val_size=0.1, \n",
    "    )    \n",
    "\n",
    "# Create SimpleCNN model\n",
    "model = SimpleCNN(\n",
    "    input_channels=5,           # HSC images have 5 channels\n",
    "    layer_width=32,             \n",
    "    num_layers=5, \n",
    "    num_classes=1,              # Regressing redshift so only 1 class\n",
    "    learning_rate=5e-3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/lparker/python_envs/astrokernel/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /mnt/sw/nix/store/b4q5asj8flwlgmaijgj1r6wbmnls5x8k-p ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import lightning as L\n",
    "\n",
    "# Set up saving checkpoints \n",
    "Checkpointing = L.pytorch.callbacks.ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_top_k=1,\n",
    "    )\n",
    "\n",
    "# Set up the training class\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=30,\n",
    "    accelerator='gpu', \n",
    "    logger=True, \n",
    "    callbacks=[\n",
    "        TrainingOnlyProgressBar(), \n",
    "        Checkpointing\n",
    "        ],\n",
    "    enable_checkpointing=True,\n",
    "    fast_dev_run=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/lparker/python_envs/astrokernel/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /mnt/sw/nix/store/b4q5asj8flwlgmaijgj1r6wbmnls5x8k-p ...\n",
      "You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type              | Params\n",
      "------------------------------------------------------\n",
      "0 | conv_layers     | Sequential        | 38.5 K\n",
      "1 | global_avg_pool | AdaptiveAvgPool2d | 0     \n",
      "2 | fc              | Linear            | 33    \n",
      "------------------------------------------------------\n",
      "38.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "38.5 K    Total params\n",
      "0.154     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6942b57dd3a74dc9bfa8ff3a4774f674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/lparker/python_envs/astrokernel/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3347551c659d4a9c96e1c2363d8b98aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    }
   ],
   "source": [
    "# Fit the trainer on the model\n",
    "trainer.fit(model=model, datamodule=photo_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model from the checkpoint\n",
    "model = SimpleCNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.5063123455773337, MSE: 0.5028639435768127\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Get R^2 values\n",
    "model.eval()\n",
    "\n",
    "y, y_hat = [], []\n",
    "for batch in photo_z.test_dataloader():\n",
    "    x, y_true = batch\n",
    "    y_pred = model(x.cuda()).detach().cpu().numpy()\n",
    "    y.append(y_true)\n",
    "    y_hat.append(y_pred)\n",
    "\n",
    "y, y_hat = np.concatenate(y), np.concatenate(y_hat)\n",
    "r2 = r2_score(y,y_hat)\n",
    "mse = np.mean((y-y_hat)**2)\n",
    "\n",
    "print(f\"R^2: {r2}, MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NormalizingFlow model\n",
    "nf = NormalizingFlow(\n",
    "    model, \n",
    "    feature_size=32, \n",
    "    num_classes=1, \n",
    "    num_flows=4, \n",
    "    hidden_dims=[32], \n",
    "    lr=1e-3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/lparker/python_envs/astrokernel/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /mnt/sw/nix/store/b4q5asj8flwlgmaijgj1r6wbmnls5x8k-p ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import lightning as L\n",
    "\n",
    "# Set up saving checkpoints \n",
    "Checkpointing = L.pytorch.callbacks.ModelCheckpoint(\n",
    "    monitor='val_nll',\n",
    "    mode='min',\n",
    "    save_top_k=1,\n",
    "    )\n",
    "\n",
    "# Set up the training class\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=30,\n",
    "    accelerator='gpu', \n",
    "    logger=True, \n",
    "    callbacks=[\n",
    "        TrainingOnlyProgressBar(), \n",
    "        Checkpointing\n",
    "        ],\n",
    "    enable_checkpointing=True,\n",
    "    fast_dev_run=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                 | Params\n",
      "-----------------------------------------------------------\n",
      "0 | feature_extractor | SimpleCNN            | 38.5 K\n",
      "1 | flow              | ConditionalFlowStack | 7.3 K \n",
      "-----------------------------------------------------------\n",
      "7.3 K     Trainable params\n",
      "38.5 K    Non-trainable params\n",
      "45.8 K    Total params\n",
      "0.183     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d85618cf61542b3904d4658263121ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/lparker/python_envs/astrokernel/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fcedcff3b7948a8aa0073fb4f4aac46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    }
   ],
   "source": [
    "# Fit the trainer on the model\n",
    "trainer.fit(model=nf, datamodule=photo_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astrokernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
